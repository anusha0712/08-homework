{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping basics for Playwright\n",
    "\n",
    "This notebook is a combination of small scraping techniques along with how to use Playwright. Along with the class notes, the [scraping section](https://jonathansoma.com/everything/scraping/) on my Everything I Know site might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import what you need to use Playwright, and start up a new browser to use for scraping. \n",
    "\n",
    "> If you end up opening a lot of Chromes/Chromiums, shutting down the Python kernel with the stop button is an easy way to make them go away! You'll have to re-run your notebook, but at least you won't have sixty icons in your dock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can use page to navigate that page\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping by class\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-class.html using their **class name**, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/by-class.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/by-class.html' method='GET'>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/by-class.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `\\n<h1 class=\"title\">How to Scrape Things</h1>\\n<h3 class=\"subhead\">Probably using Playwright</h3>\\n<p class=\"byline\">By Jonathan Soma</p>\\n`\\n\\nsetTimeout(() => {\\n    console.log(html)\\n    document.querySelector(\\'body\\').innerHTML = html\\n}, 250)</script>\\n</head><body>\\n<h1 class=\"title\">How to Scrape Things</h1>\\n<h3 class=\"subhead\">Probably using Playwright</h3>\\n<p class=\"byline\">By Jonathan Soma</p>\\n</body></html>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = await page.content()\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n"
     ]
    }
   ],
   "source": [
    "title = soup_doc.find(class_ =\"title\").string\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably using Playwright\n"
     ]
    }
   ],
   "source": [
    "subhead = soup_doc.find(class_ =\"subhead\").string\n",
    "print(subhead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Jonathan Soma\n"
     ]
    }
   ],
   "source": [
    "byline = soup_doc.find(class_ =\"byline\").string\n",
    "print(byline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping using a single tag\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-list.html, creating a dictionary out of the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/by-list.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/by-list.html' method='GET'>>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/by-list.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<!DOCTYPE html><html><head><script>\\n    const html = `<p>How to Scrape Things</p>\\n<p>Probably using Playwright</p>\\n<p>By Jonathan Soma</p>\\n`\\n\\nsetTimeout(() => {\\n    console.log(html)\\n    document.querySelector('body').innerHTML = html\\n}, 250)</script>\\n</head><body><p>How to Scrape Things</p>\\n<p>Probably using Playwright</p>\\n<p>By Jonathan Soma</p>\\n</body></html>\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmltag = await page.content()\n",
    "htmltag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_tags = BeautifulSoup(htmltag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "data = soup_doc_tags.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"title\"] = data[0].string\n",
    "all_data[\"subhead\"] = data[1].string\n",
    "all_data[\"byline\"] = data[2].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html just like you above, but use  **wait_for** to wait for the text \"Everything has shown up\" to show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html' method='GET'>>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `<p>How to Scrape Things</p>\\n<p>Probably using Playwright</p>\\n<p>By Jonathan Soma</p>\\n<p>Everything has shown up</p> \\n`\\n\\nlet pieces = html.split(\"\\\\n\")\\n\\nfunction addPiece() {\\n    document.querySelector(\\'body\\').innerHTML = document.querySelector(\\'body\\').innerHTML + pieces.shift()\\n    if(pieces.length > 0) {\\n        setTimeout(addPiece, 250)\\n    } else {\\n        setTimeout(() => {\\n            document.querySelector(\\'body\\').innerHTML = \"\"\\n            pieces = html.split(\"\\\\n\")\\n            setTimeout(addPiece, 1000)\\n        }, 2000)\\n    }\\n}\\n\\nsetTimeout(addPiece, 250)\\n</script>\\n</head><body><p>How to Scrape Things</p><p>Probably using Playwright</p><p>By Jonathan Soma</p><p>Everything has shown up</p> </body></html>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.get_by_text(\"Everything has shown up\").wait_for()\n",
    "\n",
    "html3 = await page.content()\n",
    "html3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_wait = BeautifulSoup(html3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_wait = {}\n",
    "data_wait = soup_doc_wait.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>How to Scrape Things</p>,\n",
       " <p>Probably using Playwright</p>,\n",
       " <p>By Jonathan Soma</p>,\n",
       " <p>Everything has shown up</p>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_wait[\"title\"] = data_wait[0].string\n",
    "all_data_wait[\"subhead\"] = data_wait[1].string\n",
    "all_data_wait[\"byline\"] = data_wait[2].string\n",
    "all_data_wait[\"last\"] = data_wait[3].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma',\n",
       " 'last': 'Everything has shown up'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forms\n",
    "\n",
    "Display the content of the `h1` tag on http://jonathansoma.com/columbia/interactive-scrape/inputs.html. You'll need to follow the instructions to complete the form first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/inputs.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/inputs.html' method='GET'>>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go to page\n",
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/inputs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look for drop down menu and select open\n",
    "await page.locator(\"select\").select_option('Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigate to text box and fill write answer\n",
    "await page.get_by_placeholder(\"write cat in here\").fill(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the submit button\n",
    "await page.get_by_role(\"button\", name=\"Click Me\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `<h1>You did it</h1>`\\n</script>\\n</head><body><h1>You did it</h1></body></html>'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the html after form\n",
    "html = await page.content()\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did it\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc.h1.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping a single table row\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html, creating a dictionary out of the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' method='GET'>>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<!DOCTYPE html><html><head><script>\\n    const html = `<table>\\n  <tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n</table>\\n`\\n\\nsetTimeout(() => {\\n    console.log(html)\\n    document.querySelector('body').innerHTML = html\\n}, 250)</script>\\n</head><body><table>\\n  <tbody><tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n</tbody></table>\\n</body></html>\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = await page.content()\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_row = soup_doc.find(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>How to Scrape Things</td>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_data = one_row.find_all(\"td\")\n",
    "table_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_table = {}\n",
    "\n",
    "all_data_table[\"title\"] = table_data[0].string\n",
    "all_data_table[\"subhead\"] = table_data[1].string\n",
    "all_data_table[\"byline\"] = table_data[2].string\n",
    "\n",
    "all_data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into a dictionary\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html, saving the title, subhead, and byline into a single dictionary called `book`.\n",
    "\n",
    "> Don't use pandas for this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' method='GET'>>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = await page.content()\n",
    "soup_doc = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>How to Scrape Things</td>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_row = soup_doc.find(\"tr\")\n",
    "\n",
    "table_data = one_row.find_all(\"td\")\n",
    "table_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = {}\n",
    "\n",
    "book[\"title\"] = table_data[0].string\n",
    "book[\"subhead\"] = table_data[1].string\n",
    "book[\"byline\"] = table_data[2].string\n",
    "\n",
    "book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping multiple table rows\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html, creating a list of dictionaries. Convert to a pandas dataframe with `pd.json_normalize`. Save it as `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html' method='GET'>>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<!DOCTYPE html><html><head><script>\\n    const html = `<table>\\n  <tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n  <tr>\\n    <td>How to Scrape Many Things</td>\\n    <td>But, Is It Even Possible?</td>\\n    <td>By Sonathan Joma</td>\\n  </tr>\\n  <tr>\\n    <td>The End of Scraping</td>\\n    <td>Let's All Use CSV Files</td>\\n    <td>By Amos Nathanos</td>\\n  </tr>\\n</table>\\n`\\n\\nsetTimeout(() => {\\n    document.querySelector('body').innerHTML = html\\n}, 250)</script>\\n</head><body><table>\\n  <tbody><tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n  <tr>\\n    <td>How to Scrape Many Things</td>\\n    <td>But, Is It Even Possible?</td>\\n    <td>By Sonathan Joma</td>\\n  </tr>\\n  <tr>\\n    <td>The End of Scraping</td>\\n    <td>Let's All Use CSV Files</td>\\n    <td>By Amos Nathanos</td>\\n  </tr>\\n</tbody></table>\\n</body></html>\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_html = await page.content()\n",
    "table_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_table = BeautifulSoup(table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <td>How to Scrape Things</td>\n",
       " <td>Probably using Playwright</td>\n",
       " <td>By Jonathan Soma</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <td>How to Scrape Many Things</td>\n",
       " <td>But, Is It Even Possible?</td>\n",
       " <td>By Sonathan Joma</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <td>The End of Scraping</td>\n",
       " <td>Let's All Use CSV Files</td>\n",
       " <td>By Amos Nathanos</td>\n",
       " </tr>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = soup_doc_table.find_all(\"tr\")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    one_row = {}\n",
    "    cells = row.find_all(\"td\")\n",
    "    one_row[\"title\"] = cells[0].string\n",
    "    one_row[\"subhead\"] = cells[1].string\n",
    "    one_row[\"byline\"] = cells[2].string\n",
    "    \n",
    "    full_table.append(one_row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'How to Scrape Things',\n",
       "  'subhead': 'Probably using Playwright',\n",
       "  'byline': 'By Jonathan Soma'},\n",
       " {'title': 'How to Scrape Many Things',\n",
       "  'subhead': 'But, Is It Even Possible?',\n",
       "  'byline': 'By Sonathan Joma'},\n",
       " {'title': 'The End of Scraping',\n",
       "  'subhead': \"Let's All Use CSV Files\",\n",
       "  'byline': 'By Amos Nathanos'}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(full_table)\n",
    "df.to_csv(\"output.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping an actual table\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html using pandas' HTML reading function. Save it as `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html' method='GET'>>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"http://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `<table id=\"booklist\">\\n  <tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n  <tr>\\n    <td>How to Scrape Many Things</td>\\n    <td>But, Is It Even Possible?</td>\\n    <td>By Sonathan Joma</td>\\n  </tr>\\n  <tr>\\n    <td>The End of Scraping</td>\\n    <td>Let\\'s All Use CSV Files</td>\\n    <td>By Amos Nathanos</td>\\n  </tr>\\n</table>\\n`\\n\\nsetTimeout(() => {\\n    console.log(html)\\n    document.querySelector(\\'body\\').innerHTML = html\\n}, 250)</script>\\n</head><body><table id=\"booklist\">\\n  <tbody><tr>\\n    <td>How to Scrape Things</td>\\n    <td>Probably using Playwright</td>\\n    <td>By Jonathan Soma</td>\\n  </tr>\\n  <tr>\\n    <td>How to Scrape Many Things</td>\\n    <td>But, Is It Even Possible?</td>\\n    <td>By Sonathan Joma</td>\\n  </tr>\\n  <tr>\\n    <td>The End of Scraping</td>\\n    <td>Let\\'s All Use CSV Files</td>\\n    <td>By Amos Nathanos</td>\\n  </tr>\\n</tbody></table>\\n</body></html>'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = await page.content()\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Scrape Things</td>\n",
       "      <td>Probably using Playwright</td>\n",
       "      <td>By Jonathan Soma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Scrape Many Things</td>\n",
       "      <td>But, Is It Even Possible?</td>\n",
       "      <td>By Sonathan Joma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The End of Scraping</td>\n",
       "      <td>Let's All Use CSV Files</td>\n",
       "      <td>By Amos Nathanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                          1                 2\n",
       "0       How to Scrape Things  Probably using Playwright  By Jonathan Soma\n",
       "1  How to Scrape Many Things  But, Is It Even Possible?  By Sonathan Joma\n",
       "2        The End of Scraping    Let's All Use CSV Files  By Amos Nathanos"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_html(StringIO(html))\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"output.csv\"\n",
    "\n",
    "tables[0].to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `html.parser` vs `html5lib`\n",
    "\n",
    "Here is some good HTML:\n",
    "\n",
    "```python\n",
    "html_good = \"\"\"\n",
    "<h1>This is a title</h1>\n",
    "<h2>This is a subhead</h2>\n",
    "<p>This is a paragraph</p>\n",
    "<p>This is another paragraph</p>\n",
    "\"\"\"\n",
    "\n",
    "Here is some bad HTML:\n",
    "    \n",
    "html_bad = \"\"\"\n",
    "<h1>This is a title\n",
    "<h2>This is a subhead\n",
    "<p>This is a paragraph\n",
    "<p>This is another paragraph\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "When you're using BeautifulSoup, you can use different parsers, including `html.parser`, `html5lib` and `lxml`. Try both the good HTML and bad HTML with each parser and use `print(soup_doc.prettify())` to view the difference.\n",
    "\n",
    "What is different about each one?\n",
    "\n",
    "> You'll need to `pip install` for both html5lib and lxml. Since you aren't important them, they're coming from BeautifulSoup, you'll need to do **Kernel > Restart** and run from the top after installing to have them work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_good = \"\"\"\n",
    "<h1>This is a title</h1>\n",
    "<h2>This is a subhead</h2>\n",
    "<p>This is a paragraph</p>\n",
    "<p>This is another paragraph</p>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "html_bad = \"\"\"\n",
    "<h1>This is a title\n",
    "<h2>This is a subhead\n",
    "<p>This is a paragraph\n",
    "<p>This is another paragraph\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good HTML 2 parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_good_html5lib = BeautifulSoup(html_good, \"html5lib\")\n",
    "soup_doc_good_lxml = BeautifulSoup(html_good, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc_good_html5lib.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc_good_lxml.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad HTML 2 parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_doc_bad_html5lib = BeautifulSoup(html_bad, \"html5lib\")\n",
    "soup_doc_bad_lxml = BeautifulSoup(html_bad, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "   <p>\n",
      "    This is a paragraph\n",
      "   </p>\n",
      "   <p>\n",
      "    This is another paragraph\n",
      "   </p>\n",
      "  </h2>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc_bad_html5lib.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "   <h2>\n",
      "    This is a subhead\n",
      "   </h2>\n",
      "  </h1>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc_bad_lxml.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to me that if the html is generally laid out well, parsers give you decently similar results. But if the html itself is bad, they give you different results and you might have to test out how they look so you can access the right tags? Html5lib seems to give a better structure for this intuitively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
